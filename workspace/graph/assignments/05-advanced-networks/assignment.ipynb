{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五次作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次作业我们强化对GAE和VGAE的实践。具体地，我们用它们来完成（无监督）节点分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 课后习题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 图的自编码器和图卷积神经网络的区别是什么？\n",
    "2. 图的变分自编码器比起图的自编码器的优点是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次作业我们使用Cora数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up session:\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_samples(g, k=19, seed=None):\n",
    "    \"\"\" generate negative sample dataset for edge prediction whose size is k times of positive sample dataset\n",
    "    \"\"\"\n",
    "    # set seed for numpy.random if provided:\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # parse graph configuration:\n",
    "    num_nodes = g.num_nodes() - 1\n",
    "    adj = g.adj(transpose=False, ctx='cpu', scipy_fmt='csr')\n",
    "\n",
    "    # generate negative samples:\n",
    "    num_neg_samples = k*g.num_edges()\n",
    "    neg_samples = set()\n",
    "    while len(neg_samples) < num_neg_samples:\n",
    "        proposal = np.random.randint(0, num_nodes, [num_neg_samples, 2])\n",
    "\n",
    "        proposal = set(\n",
    "            list(map(tuple, proposal[adj[proposal[:, 0], proposal[:, 1]].A1 < 1.0]))\n",
    "        )\n",
    "\n",
    "        neg_samples = neg_samples.union(proposal)\n",
    "    \n",
    "    # format:\n",
    "    neg_samples = list(neg_samples)[:num_neg_samples]\n",
    "    neg_samples = tuple(zip(*neg_samples))\n",
    "    \n",
    "    # done:\n",
    "    return dgl.graph(neg_samples, num_nodes=g.num_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_test_split(g, train_ratio=0.85, valid_ratio=0.05):\n",
    "    \"\"\" get train-validation-test split of edges\n",
    "    \"\"\"\n",
    "    edge_idx = np.arange(g.num_edges())\n",
    "    np.random.shuffle(edge_idx)\n",
    "    \n",
    "    num_train = int(train_ratio*g.num_edges())\n",
    "    num_valid = int(valid_ratio*g.num_edges())\n",
    "    \n",
    "    train_edge_idx = edge_idx[:num_train]\n",
    "    valid_edge_idx = edge_idx[num_train:(num_train+num_valid)]\n",
    "    test_edge_idx = edge_idx[(num_train+num_valid):]\n",
    "    \n",
    "    return (train_edge_idx, valid_edge_idx, test_edge_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "# set device:\n",
    "device = torch.device('cuda:0')\n",
    "# load dataset:\n",
    "dataset = CoraGraphDataset('./data')\n",
    "\n",
    "# get dataset\n",
    "pos_g = dataset[0]\n",
    "neg_g = generate_negative_samples(pos_g)\n",
    "\n",
    "# train-validation-test split:\n",
    "pos_train_edge_idx, pos_valid_edge_idx, pos_test_edge_idx = get_train_valid_test_split(pos_g)\n",
    "neg_train_edge_idx, neg_valid_edge_idx, neg_test_edge_idx = get_train_valid_test_split(neg_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=10556,\n",
       "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={'__orig__': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset overview, positive\n",
    "pos_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=200564,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset overview, negative\n",
    "neg_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义GAE和VGAE\n",
    "首先请同学们定义两个类：GAE和VGAE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    \"\"\" deep GCN encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        \"\"\" init layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gcn1 = GraphConv(\n",
    "            in_feats=in_feats, out_feats=2*out_feats, \n",
    "            weight=True, bias=True, \n",
    "            activation=F.relu, \n",
    "            allow_zero_in_degree=True\n",
    "        )\n",
    "        \n",
    "        self.output = GraphConv(\n",
    "            in_feats=2*out_feats, out_feats=out_feats, \n",
    "            weight=True, bias=True, \n",
    "            activation=None, \n",
    "            allow_zero_in_degree=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, g, x):\n",
    "        \"\"\" forward propagation\n",
    "        \"\"\"\n",
    "        h = self.gcn1(g, x)\n",
    "        h = self.output(g, h)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "class InnerProductDecoder(torch.nn.Module):\n",
    "    \"\"\" inner product decoder\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, g, z, sigmoid=True):\n",
    "        \"\"\" forward propagation\n",
    "        \"\"\"\n",
    "        g.ndata['z'] = z\n",
    "        g.apply_edges(fn.u_dot_v('z', 'z', 'logit'))\n",
    "        logit = g.edata['logit'].sum(dim=1)\n",
    "        \n",
    "        return torch.sigmoid(logit) if sigmoid else logit\n",
    "    \n",
    "class GAE(torch.nn.Module):\n",
    "    \"\"\" graph autoencoder\n",
    "    \"\"\"\n",
    "    EPSILON = 1e-16\n",
    "    \n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def encode(self, *args, **kwargs):\n",
    "        \"\"\" encode\n",
    "        \"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "    \n",
    "    def decode(self, *args, **kwargs):\n",
    "        \"\"\" decode\n",
    "        \"\"\"\n",
    "        return self.decoder(*args, **kwargs)\n",
    "    \n",
    "    def get_reconstruction_loss(self, z, pos_g, neg_g, pos_edge_idx, neg_edge_idx):\n",
    "        \"\"\" get edge reconstruction loss\n",
    "        \"\"\"\n",
    "        pos_edge_prob = self.decode(g=pos_g, z=z)[pos_edge_idx] + GAE.EPSILON\n",
    "        neg_edge_prob = 1.0 - self.decode(g=neg_g, z=z)[neg_edge_idx] + GAE.EPSILON\n",
    "        \n",
    "        pos_edge_loss = (-torch.log(pos_edge_prob)).mean()\n",
    "        neg_edge_loss = (-torch.log(neg_edge_prob)).mean()\n",
    "        \n",
    "        return pos_edge_loss + neg_edge_loss\n",
    "    \n",
    "    def get_loss(self, *args, **kwargs):\n",
    "        \"\"\" wrapper for loss function evaluation\n",
    "        \"\"\"\n",
    "        return self.get_reconstruction_loss(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    MAX_LOGSTD = 10.0\n",
    "    \n",
    "    def __init__(self, in_feats, out_feats, variation_scale=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # gcn1:\n",
    "        self.gcn1 = GraphConv(\n",
    "            in_feats=in_feats, out_feats=2*out_feats, \n",
    "            weight=True, bias=True, \n",
    "            activation=F.relu, \n",
    "            allow_zero_in_degree=True\n",
    "        )\n",
    "        \n",
    "        # output, mu\n",
    "        self.output_mu = GraphConv(\n",
    "            in_feats=2*out_feats, out_feats=out_feats, \n",
    "            weight=True, bias=True, \n",
    "            activation=None, \n",
    "            allow_zero_in_degree=True\n",
    "        )\n",
    "        \n",
    "        # output, log(std):\n",
    "        self.output_logstd = GraphConv(\n",
    "            in_feats=2*out_feats, out_feats=out_feats, \n",
    "            weight=True, bias=True, \n",
    "            activation=None, \n",
    "            allow_zero_in_degree=True\n",
    "        )\n",
    "        \n",
    "        # for sampling from encoded Gaussian\n",
    "        self.output_std_scale = variation_scale\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        \"\"\" forward propagation\n",
    "        \"\"\"\n",
    "        h = self.gcn1(g, x)\n",
    "        \n",
    "        mu = self.output_mu(g, h)\n",
    "        logstd = self.output_logstd(g, h)\n",
    "        \n",
    "        return (mu, logstd)\n",
    "    \n",
    "    def sample_from_encoded_gaussian(self, mu, logstd, training):\n",
    "        \"\"\" sample from encoded Gaussian\n",
    "        \"\"\"\n",
    "        if training:\n",
    "            return mu + (2*torch.randn_like(logstd) - 1) * self.output_std_scale * torch.exp(logstd)\n",
    "        \n",
    "        return mu\n",
    "    \n",
    "class VGAE(GAE): \n",
    "    \"\"\"变分自编码器。继承自GAE这个类，可以使用GAE里面定义的函数。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__(encoder=encoder, decoder=decoder)\n",
    "    \n",
    "    \n",
    "    def encode(self, *args, **kwargs):\n",
    "        \"\"\" encode\n",
    "        \"\"\"\n",
    "        # get encoding Gaussian:\n",
    "        self.__mu__, self.__logstd__ = self.encoder(*args, **kwargs)\n",
    "        \n",
    "        # limit standard deviation scale:\n",
    "        self.__logstd__ = self.__logstd__.clamp(max=self.encoder.MAX_LOGSTD)\n",
    "        \n",
    "        # sample from encoding Gaussian:\n",
    "        return self.encoder.sample_from_encoded_gaussian(\n",
    "            self.__mu__, self.__logstd__, \n",
    "            self.training\n",
    "        )\n",
    "\n",
    "    def get_regulation_loss(self, mu=None, logstd=None):\n",
    "        \"\"\" get encoding Gaussian regulation loss\n",
    "        \"\"\"\n",
    "        mu = mu if not mu is None else self.__mu__\n",
    "        logstd = logstd.clamp(max=self.encoder.MAX_LOGSTD) if not logstd is None else self.__logstd__\n",
    "        \n",
    "        # KL(p||q), with p as actual Gaussian and q as prior Gaussian:\n",
    "        return -0.5*torch.mean(\n",
    "            torch.mean(1.0 + 2*logstd - mu**2 - logstd.exp()**2, dim=1)\n",
    "        )\n",
    "    \n",
    "    def get_loss(self, *args, **kwargs):\n",
    "        \"\"\" wrapper for loss function evaluation\n",
    "        \"\"\"\n",
    "        # TODO: the introduction of Gaussian prior regulation seems to hurt the performance\n",
    "        return super().get_loss(*args, **kwargs) # + self.get_regulation_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这部分请同学们自由发挥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, lr=0.01, weight_decay=5e-4, epochs=1000, validation_step_size=125):\n",
    "    \"\"\" train (variational) autoencoder\n",
    "    \"\"\"\n",
    "    # parse dataset:\n",
    "    (pos, neg) = g\n",
    "    (pos_g, pos_train_edge_idx, pos_valid_edge_idx) = pos\n",
    "    (neg_g, neg_train_edge_idx, neg_valid_edge_idx) = neg\n",
    "    \n",
    "    # init optimizer:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    print(\n",
    "        \"\"\"Training...\"\"\"\n",
    "    )\n",
    "    \n",
    "    # optimize:\n",
    "    for i in range(epochs + 1):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # get encoding:\n",
    "        z = model.encode(g=pos_g, x=pos_g.ndata['feat'])\n",
    "        # get loss:\n",
    "        train_loss = model.get_loss(z, pos_g, neg_g, pos_train_edge_idx, neg_train_edge_idx)\n",
    "        \n",
    "        # back propagation\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # do validation\n",
    "        if i % validation_step_size == 0:\n",
    "            valid_loss = model.get_loss(z, pos_g, neg_g, pos_valid_edge_idx, neg_valid_edge_idx)\n",
    "            print(\n",
    "                \"\"\"\\tEpoch {}:\\n\"\"\"\n",
    "                \"\"\"\\t\\t training / validation losses: {:.4f} / {:.4f}\"\"\".format(\n",
    "                    i, \n",
    "                    train_loss.item(), valid_loss.item()\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, pos_g, neg_g, pos_edge_idx, neg_edge_idx):\n",
    "    model.eval()\n",
    "    \n",
    "    x = pos_g.ndata['feat']\n",
    "    \n",
    "    pos_z = model.encode(g=pos_g, x=x)\n",
    "    neg_z = model.encode(g=neg_g, x=x)\n",
    "    \n",
    "    pos_y = pos_z.new_ones(pos_edge_idx.size)\n",
    "    neg_y = neg_z.new_zeros(neg_edge_idx.size)\n",
    "    y = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "    pos_pred = model.decoder(pos_g, pos_z)[pos_edge_idx]\n",
    "    neg_pred = model.decoder(neg_g, neg_z)[neg_edge_idx]\n",
    "    pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "    y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "\n",
    "    return roc_auc_score(y, pred), average_precision_score(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\tEpoch 0:\n",
      "\t\t training / validation losses: 1.3862 / 1.3862\n",
      "\tEpoch 125:\n",
      "\t\t training / validation losses: 1.1126 / 1.1431\n",
      "\tEpoch 250:\n",
      "\t\t training / validation losses: 1.1006 / 1.1350\n",
      "\tEpoch 375:\n",
      "\t\t training / validation losses: 1.0989 / 1.1346\n",
      "\tEpoch 500:\n",
      "\t\t training / validation losses: 1.0985 / 1.1343\n",
      "\tEpoch 625:\n",
      "\t\t training / validation losses: 1.0985 / 1.1333\n",
      "\tEpoch 750:\n",
      "\t\t training / validation losses: 1.0983 / 1.1339\n",
      "\tEpoch 875:\n",
      "\t\t training / validation losses: 1.0983 / 1.1334\n",
      "\tEpoch 1000:\n",
      "\t\t training / validation losses: 1.0982 / 1.1337\n",
      "\tEpoch 1125:\n",
      "\t\t training / validation losses: 1.0982 / 1.1335\n",
      "\tEpoch 1250:\n",
      "\t\t training / validation losses: 1.0982 / 1.1338\n",
      "\tEpoch 1375:\n",
      "\t\t training / validation losses: 1.0984 / 1.1333\n",
      "\tEpoch 1500:\n",
      "\t\t training / validation losses: 1.0984 / 1.1344\n",
      "\tEpoch 1625:\n",
      "\t\t training / validation losses: 1.0982 / 1.1334\n",
      "\tEpoch 1750:\n",
      "\t\t training / validation losses: 1.0983 / 1.1333\n",
      "\tEpoch 1875:\n",
      "\t\t training / validation losses: 1.0983 / 1.1342\n",
      "\tEpoch 2000:\n",
      "\t\t training / validation losses: 1.0982 / 1.1338\n",
      "\tEpoch 2125:\n",
      "\t\t training / validation losses: 1.0983 / 1.1333\n",
      "\tEpoch 2250:\n",
      "\t\t training / validation losses: 1.0983 / 1.1333\n",
      "\tEpoch 2375:\n",
      "\t\t training / validation losses: 1.0982 / 1.1340\n",
      "\tEpoch 2500:\n",
      "\t\t training / validation losses: 1.0984 / 1.1345\n"
     ]
    }
   ],
   "source": [
    "# config:\n",
    "in_feats, out_feats = pos_g.ndata['feat'].shape[1], 16\n",
    "\n",
    "# init:\n",
    "gae = GAE(\n",
    "    encoder=GCNEncoder(in_feats, out_feats),\n",
    "    decoder=InnerProductDecoder()\n",
    ").to(device)\n",
    "pos_g = pos_g.to(device)\n",
    "neg_g = neg_g.to(device)\n",
    "\n",
    "# training:\n",
    "train(\n",
    "    # model:\n",
    "    gae, \n",
    "    # dataset:\n",
    "    (\n",
    "        (pos_g, pos_train_edge_idx, pos_valid_edge_idx),\n",
    "        (neg_g, neg_train_edge_idx, neg_valid_edge_idx)\n",
    "    ),\n",
    "    # optimizer:\n",
    "    lr=5e-3, weight_decay=5e-4, \n",
    "    # training and validation:\n",
    "    epochs=2500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAE Edge Prediction Summary:\n",
      "\t ROC AUC / Accuracy: 0.9263 / 0.9275\n"
     ]
    }
   ],
   "source": [
    "# test:\n",
    "(roc_auc, acc) = test(\n",
    "    gae,\n",
    "    pos_g, neg_g,\n",
    "    pos_test_edge_idx, neg_test_edge_idx\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\"\"GAE Edge Prediction Summary:\\n\"\"\"\n",
    "    \"\"\"\\t ROC AUC / Accuracy: {:.4f} / {:.4f}\"\"\".format(\n",
    "        roc_auc, acc\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding:\n",
    "embedding_gae = gae.encode(g=pos_g, x=pos_g.ndata['feat']).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 VGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\tEpoch 0:\n",
      "\t\t training / validation losses: 34.9745 / 34.9409\n",
      "\tEpoch 125:\n",
      "\t\t training / validation losses: 1.3785 / 1.3834\n",
      "\tEpoch 250:\n",
      "\t\t training / validation losses: 1.3324 / 1.3343\n",
      "\tEpoch 375:\n",
      "\t\t training / validation losses: 1.3203 / 1.3391\n",
      "\tEpoch 500:\n",
      "\t\t training / validation losses: 1.3150 / 1.3203\n",
      "\tEpoch 625:\n",
      "\t\t training / validation losses: 1.3096 / 1.3180\n",
      "\tEpoch 750:\n",
      "\t\t training / validation losses: 1.2992 / 1.3112\n",
      "\tEpoch 875:\n",
      "\t\t training / validation losses: 1.2788 / 1.2919\n",
      "\tEpoch 1000:\n",
      "\t\t training / validation losses: 1.1771 / 1.2069\n",
      "\tEpoch 1125:\n",
      "\t\t training / validation losses: 1.1417 / 1.1736\n",
      "\tEpoch 1250:\n",
      "\t\t training / validation losses: 1.1238 / 1.1534\n",
      "\tEpoch 1375:\n",
      "\t\t training / validation losses: 1.0772 / 1.1054\n",
      "\tEpoch 1500:\n",
      "\t\t training / validation losses: 1.0451 / 1.0670\n",
      "\tEpoch 1625:\n",
      "\t\t training / validation losses: 1.0329 / 1.0555\n",
      "\tEpoch 1750:\n",
      "\t\t training / validation losses: 1.0211 / 1.0507\n",
      "\tEpoch 1875:\n",
      "\t\t training / validation losses: 1.0121 / 1.0378\n",
      "\tEpoch 2000:\n",
      "\t\t training / validation losses: 1.0087 / 1.0353\n",
      "\tEpoch 2125:\n",
      "\t\t training / validation losses: 1.0087 / 1.0346\n",
      "\tEpoch 2250:\n",
      "\t\t training / validation losses: 1.0059 / 1.0302\n",
      "\tEpoch 2375:\n",
      "\t\t training / validation losses: 1.0048 / 1.0303\n",
      "\tEpoch 2500:\n",
      "\t\t training / validation losses: 1.0023 / 1.0269\n"
     ]
    }
   ],
   "source": [
    "# config:\n",
    "in_feats, out_feats = pos_g.ndata['feat'].shape[1], 16\n",
    "\n",
    "# init:\n",
    "vgae = VGAE(\n",
    "    encoder=VariationalGCNEncoder(in_feats, out_feats),\n",
    "    decoder=InnerProductDecoder()\n",
    ").to(device)\n",
    "\n",
    "pos_g = pos_g.to(device)\n",
    "neg_g = neg_g.to(device)\n",
    "\n",
    "# training:\n",
    "train(\n",
    "    # model:\n",
    "    vgae, \n",
    "    # dataset:\n",
    "    (\n",
    "        (pos_g, pos_train_edge_idx, pos_valid_edge_idx),\n",
    "        (neg_g, neg_train_edge_idx, neg_valid_edge_idx)\n",
    "    ),\n",
    "    # optimizer:\n",
    "    lr=5e-3, weight_decay=5e-4, \n",
    "    # training and validation:\n",
    "    epochs=2500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational GAE Edge Prediction Summary:\n",
      "\t ROC AUC / Accuracy: 0.9833 / 0.9838\n"
     ]
    }
   ],
   "source": [
    "# test:\n",
    "(roc_auc, acc) = test(\n",
    "    vgae,\n",
    "    pos_g, neg_g,\n",
    "    pos_test_edge_idx, neg_test_edge_idx\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\"\"Variational GAE Edge Prediction Summary:\\n\"\"\"\n",
    "    \"\"\"\\t ROC AUC / Accuracy: {:.4f} / {:.4f}\"\"\".format(\n",
    "        roc_auc, acc\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding:\n",
    "embedding_vgae = vgae.encode(g=pos_g, x=pos_g.ndata['feat']).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 测试模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练一个线性模型（比如逻辑回归模型）来预测节点的标签，并输出预测准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_node_classification(\n",
    "    embeddings, labels, \n",
    "    train_mask, test_mask, \n",
    "    normalize_embedding=True, \n",
    "    max_iter=1000\n",
    "):\n",
    "    \"\"\" use single-layer MLP for node label prediction using (variational) graph auto-encoder embeddings\n",
    "    \"\"\"\n",
    "    # normalize:\n",
    "    X = embeddings\n",
    "    if normalize_embedding:\n",
    "        X = normalize(embeddings)\n",
    "    \n",
    "    # split train-test sets:\n",
    "    X_train, y_train = X[train_mask, :], labels[train_mask]\n",
    "    X_test, y_test = X[test_mask, :], labels[test_mask]\n",
    "    \n",
    "    # build classifier:\n",
    "    clf = MLPClassifier(\n",
    "        random_state=42,\n",
    "        hidden_layer_sizes=[32],\n",
    "        max_iter=max_iter\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction:\n",
    "    preds = clf.predict(X_test)\n",
    "    \n",
    "    # get classification report:\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_true=y_test, y_pred=preds\n",
    "        )\n",
    "    )\n",
    "    # get accuracy score:\n",
    "    test_acc = accuracy_score(y_true=y_test, y_pred=preds)\n",
    "    \n",
    "    return preds, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       130\n",
      "           1       0.15      0.95      0.25        91\n",
      "           2       0.00      0.00      0.00       144\n",
      "           3       0.00      0.00      0.00       319\n",
      "           4       0.34      0.92      0.49       149\n",
      "           5       1.00      0.01      0.02       103\n",
      "           6       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.22      1000\n",
      "   macro avg       0.21      0.27      0.11      1000\n",
      "weighted avg       0.17      0.22      0.10      1000\n",
      "\n",
      "GAE Test Accuracy: 0.2240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/graph/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda/envs/graph/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda/envs/graph/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds, test_acc = evaluate_node_classification(\n",
    "    embedding_gae, pos_g.ndata['label'].cpu().detach().numpy(), \n",
    "    pos_g.ndata['train_mask'].cpu().detach().numpy(), pos_g.ndata['test_mask'].cpu().detach().numpy()\n",
    ")\n",
    "\n",
    "print('GAE Test Accuracy: %.4f' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.51      0.46       130\n",
      "           1       0.38      0.69      0.49        91\n",
      "           2       0.78      0.88      0.83       144\n",
      "           3       0.74      0.36      0.49       319\n",
      "           4       0.70      0.54      0.61       149\n",
      "           5       0.46      0.70      0.55       103\n",
      "           6       0.28      0.36      0.32        64\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.54      0.58      0.53      1000\n",
      "weighted avg       0.61      0.55      0.55      1000\n",
      "\n",
      "Variational GAE Test Accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/graph/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "preds, test_acc = evaluate_node_classification(\n",
    "    embedding_vgae, pos_g.ndata['label'].cpu().detach().numpy(), \n",
    "    pos_g.ndata['train_mask'].cpu().detach().numpy(), pos_g.ndata['test_mask'].cpu().detach().numpy()\n",
    ")\n",
    "\n",
    "print('Variational GAE Test Accuracy: %.4f' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里本次作业就结束了。这次的任务其实是无监督的节点分类问题。可以看到，我们会使用一些和前面DeepWalk作业中相似的代码。同学可以讲DeepWalk和GAE/VGAE的结果做一个比较，看看谁在这个任务上效果更好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
